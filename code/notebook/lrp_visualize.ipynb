{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run relevance backout here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import shuffle\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from util.optimization import BERTAdam\n",
    "from util.processor import *\n",
    "\n",
    "\n",
    "from util.tokenization import *\n",
    "\n",
    "from util.evaluation import *\n",
    "\n",
    "from util.train_helper import *\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# this imports most of the helpers needed to eval the model\n",
    "from run_classifier import *\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "RETRAIN = False\n",
    "vocab_data_dir = \"../../models/BERT-Google/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from numpy import newaxis as na\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# The function to back-out layerwise attended relevance scores.\n",
    "#\n",
    "##############################################################################\n",
    "def rescale_lrp(post_A, inp_relevances):\n",
    "    inp_relevances = torch.abs(inp_relevances)\n",
    "    if len(post_A.shape) == 2:\n",
    "        ref_scale = torch.sum(post_A, dim=-1, keepdim=True) + 1e-7\n",
    "        inp_scale = torch.sum(inp_relevances, dim=-1, keepdim=True) + 1e-7\n",
    "    elif len(post_A.shape) == 3:\n",
    "        ref_scale = post_A.sum(dim=-1, keepdim=True).sum(dim=-1, keepdim=True) + 1e-7\n",
    "        inp_scale = inp_relevances.sum(dim=-1, keepdim=True).sum(dim=-1, keepdim=True) + 1e-7\n",
    "    scaler = ref_scale / inp_scale\n",
    "    inp_relevances = inp_relevances * scaler\n",
    "    return inp_relevances\n",
    "\n",
    "def backprop_lrp_fc(weight, bias, activations, R, \n",
    "                    eps=1e-7, alpha=0.5, debug=False):\n",
    "    beta = 1.0 - alpha\n",
    "    \n",
    "    weight_p = torch.clamp(weight, min=0.0)\n",
    "    bias_p = torch.clamp(bias, min=0.0)    \n",
    "    z_p = torch.matmul(activations, weight_p.T) + bias_p + eps\n",
    "    s_p = R / z_p\n",
    "    c_p = torch.matmul(s_p, weight_p)\n",
    "    \n",
    "    weight_n = torch.clamp(weight, max=0.0)\n",
    "    bias_n = torch.clamp(bias, max=0.0)\n",
    "    z_n = torch.matmul(activations, weight_n.T) + bias_n - eps \n",
    "    s_n = R / z_n\n",
    "    c_n = torch.matmul(s_n, weight_n)\n",
    "\n",
    "    R_c = activations * (alpha * c_p + beta * c_n)\n",
    "    \n",
    "    R_c = rescale_lrp(R, R_c)\n",
    "\n",
    "    return R_c\n",
    "\n",
    "def backprop_lrp_nl(weight, activations, R, \n",
    "                    eps=1e-7, alpha=0.5, debug=False):\n",
    "    \"\"\"\n",
    "    This is for non-linear linear lrp.\n",
    "    We use jacobian and first term of Taylor expansions.\n",
    "    weight: [b, l, h_out, h_in]\n",
    "    activations: [b, l, h_in]\n",
    "    R: [b, l, h_out]\n",
    "    \"\"\"\n",
    "    beta = 1.0 - alpha\n",
    "    R = R.unsqueeze(dim=2) # [b, l, 1, h_out]\n",
    "    activations = activations.unsqueeze(dim=2) # [b, l, 1, h_in]\n",
    "\n",
    "    weight_p = torch.clamp(weight, min=0.0) \n",
    "    z_p = torch.matmul(activations, weight_p.transpose(2,3)) + eps\n",
    "    s_p = R / z_p # [b, l, 1, h_out]\n",
    "    c_p = torch.matmul(s_p, weight_p) # [b, l, 1, h_in]\n",
    "    \n",
    "    weight_n = torch.clamp(weight, max=0.0)\n",
    "    z_n = torch.matmul(activations, weight_n.transpose(2,3)) + eps \n",
    "    s_n = R / z_n\n",
    "    c_n = torch.matmul(s_n, weight_n)\n",
    "\n",
    "    R_c = activations * (alpha * c_p + beta * c_n)\n",
    "    \n",
    "    R_c = R_c.squeeze(dim=2)\n",
    "    R = R.squeeze(dim=2)\n",
    "    R_c = rescale_lrp(R, R_c)\n",
    "\n",
    "    return R_c\n",
    "\n",
    "def rescale_jacobian(output_relevance, *input_relevances, batch_axes=(0,)):\n",
    "    assert isinstance(batch_axes, (tuple, list))\n",
    "    get_summation_axes = lambda tensor: tuple(i for i in range(len(tensor.shape)) if i not in batch_axes)\n",
    "    ref_scale = abs(output_relevance).sum(dim=get_summation_axes(output_relevance), keepdim=True)\n",
    "    inp_scales = [abs(inp).sum(dim=get_summation_axes(inp), keepdim=True) for inp in input_relevances]\n",
    "    total_inp_scale = sum(inp_scales) + 1e-7\n",
    "    input_relevances = [inp * (ref_scale / total_inp_scale) for inp in input_relevances]\n",
    "    return input_relevances[0] if len(input_relevances) == 1 else input_relevances\n",
    "\n",
    "def backprop_lrp_jacobian(jacobians, output, R, inps, eps=1e-7, alpha=0.5, batch_axes=(0,)):\n",
    "    \"\"\"\n",
    "    computes input relevance given output_relevance using z+ rule\n",
    "    works for linear layers, convolutions, poolings, etc.\n",
    "    notation from DOI:10.1371/journal.pone.0130140, Eq 60\n",
    "    \"\"\"\n",
    "    \n",
    "    beta = 1.0 - alpha\n",
    "    inps = [inp for inp in inps]\n",
    "\n",
    "    reference_inputs = tuple(map(torch.zeros_like, inps))\n",
    "    assert len(reference_inputs) == len(inps)\n",
    "\n",
    "    flat_output_relevance = R.reshape([-1])\n",
    "    output_size = flat_output_relevance.shape[0]\n",
    "\n",
    "    assert len(jacobians) == len(inps)\n",
    "\n",
    "    jac_flat_components = [jac.reshape([output_size, -1]) for jac in jacobians]\n",
    "    # ^-- list of [output_size, input_size] for each input\n",
    "    flat_jacobian = torch.cat(jac_flat_components, dim=-1)  # [output_size, combined_input_size]\n",
    "\n",
    "    # 2. multiply jacobian by input to get unnormalized relevances, add bias\n",
    "    flat_input = torch.cat([inp.reshape([-1]) for inp in inps], dim=-1)  # [combined_input_size]\n",
    "    flat_reference_input = torch.cat([ref.reshape([-1]) for ref in reference_inputs], dim=-1)\n",
    "    import operator\n",
    "    from functools import reduce \n",
    "    num_samples = reduce(operator.mul, [output.shape[batch_axis] for batch_axis in batch_axes], 1)\n",
    "    input_size_per_sample = flat_reference_input.shape[0] // num_samples\n",
    "    flat_impact = (flat_jacobian * flat_input[None, :])\n",
    "    # ^-- [output_size, combined_input_size], aka z_{j<-i}\n",
    "\n",
    "    # 3. normalize positive and negative relevance separately and add them with coefficients\n",
    "    flat_positive_impact = torch.clamp(flat_impact, min=0.0)\n",
    "    flat_positive_normalizer = flat_positive_impact.sum(dim=0, keepdim=True) + eps\n",
    "    flat_positive_relevance = flat_positive_impact / flat_positive_normalizer\n",
    "\n",
    "    flat_negative_impact = torch.clamp(flat_impact, max=0.0)\n",
    "    flat_negative_normalizer = flat_negative_impact.sum(dim=0, keepdim=True) - eps\n",
    "    flat_negative_relevance = flat_negative_impact / flat_negative_normalizer\n",
    "    flat_total_relevance_transition = alpha * flat_positive_relevance + beta * flat_negative_relevance\n",
    "\n",
    "    flat_input_relevance = torch.einsum('o,oi->i', flat_output_relevance, flat_total_relevance_transition)\n",
    "    # ^-- [combined_input_size]\n",
    "\n",
    "    # 5. unpack flat_inp_relevance back into individual tensors\n",
    "    input_relevances = []\n",
    "    offset = 0\n",
    "    for inp in inps:\n",
    "        inp_size = inp.reshape([-1]).shape[0]\n",
    "        inp_relevance = flat_input_relevance[offset: offset + inp_size].reshape(inp.shape)\n",
    "        inp_relevance = inp_relevance.contiguous()\n",
    "        input_relevances.append(inp_relevance)\n",
    "        offset = offset + inp_size\n",
    "    \n",
    "    return rescale_jacobian(R, *input_relevances, batch_axes=batch_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "# Reference: https://github.com/huggingface/pytorch-pretrained-BERT\n",
    "\n",
    "\"\"\"PyTorch BERT model.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "\n",
    "import six\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import collections\n",
    "from functools import partial\n",
    "\n",
    "from util.lrp import *\n",
    "\n",
    "# access global vars here\n",
    "global func_inputs\n",
    "global func_activations\n",
    "func_inputs = collections.defaultdict(list)\n",
    "func_activations = collections.defaultdict(list)\n",
    "\n",
    "def get_inputivation(name):\n",
    "    def hook(model, input, output):\n",
    "        func_inputs[name] = [_in for _in in input]\n",
    "    return hook\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        func_activations[name] = output\n",
    "    return hook\n",
    "\n",
    "def get_activation_multi(name):\n",
    "    def hook(model, input, output):\n",
    "        func_activations[name] = [_out for _out in output]\n",
    "    return hook\n",
    "\n",
    "# TODO: make this init as a part of the model init\n",
    "def init_hooks_lrp(model):\n",
    "    \"\"\"\n",
    "    Initialize all the hooks required for full lrp for BERT model.\n",
    "    \"\"\"\n",
    "    # in order to backout all the lrp through layers\n",
    "    # you need to register hooks here.\n",
    "\n",
    "    model.classifier.register_forward_hook(\n",
    "        get_inputivation('model.classifier'))\n",
    "    model.classifier.register_forward_hook(\n",
    "        get_activation('model.classifier'))\n",
    "    model.bert.pooler.dense.register_forward_hook(\n",
    "        get_inputivation('model.bert.pooler.dense'))\n",
    "    model.bert.pooler.dense.register_forward_hook(\n",
    "        get_activation('model.bert.pooler.dense'))\n",
    "    model.bert.pooler.register_forward_hook(\n",
    "        get_inputivation('model.bert.pooler'))\n",
    "    model.bert.pooler.register_forward_hook(\n",
    "        get_activation('model.bert.pooler'))\n",
    "\n",
    "    model.bert.embeddings.word_embeddings.register_forward_hook(\n",
    "        get_activation('model.bert.embeddings.word_embeddings'))\n",
    "    model.bert.embeddings.register_forward_hook(\n",
    "        get_activation('model.bert.embeddings'))\n",
    "\n",
    "    layer_module_index = 0\n",
    "    for module_layer in model.bert.encoder.layer:\n",
    "        \n",
    "        ## Encoder Output Layer\n",
    "        layer_name_output_layernorm = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.output.LayerNorm'\n",
    "        module_layer.output.LayerNorm.register_forward_hook(\n",
    "            get_inputivation(layer_name_output_layernorm))\n",
    "\n",
    "        layer_name_dense = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.output.dense'\n",
    "        module_layer.output.dense.register_forward_hook(\n",
    "            get_inputivation(layer_name_dense))\n",
    "        module_layer.output.dense.register_forward_hook(\n",
    "            get_activation(layer_name_dense))\n",
    "\n",
    "        layer_name_output = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.output'\n",
    "        module_layer.output.register_forward_hook(\n",
    "            get_inputivation(layer_name_output))\n",
    "        module_layer.output.register_forward_hook(\n",
    "            get_activation(layer_name_output))\n",
    "        \n",
    "        ## Encoder Intermediate Layer\n",
    "        layer_name_inter = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.intermediate.dense'\n",
    "        module_layer.intermediate.dense.register_forward_hook(\n",
    "            get_inputivation(layer_name_inter))\n",
    "        module_layer.intermediate.dense.register_forward_hook(\n",
    "            get_activation(layer_name_inter))\n",
    "\n",
    "        layer_name_attn_layernorm = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.output.LayerNorm'\n",
    "        module_layer.attention.output.LayerNorm.register_forward_hook(\n",
    "            get_inputivation(layer_name_attn_layernorm))\n",
    "        \n",
    "        layer_name_attn = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.output.dense'\n",
    "        module_layer.attention.output.dense.register_forward_hook(\n",
    "            get_inputivation(layer_name_attn))\n",
    "        module_layer.attention.output.dense.register_forward_hook(\n",
    "            get_activation(layer_name_attn))\n",
    "\n",
    "        layer_name_attn_output = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.output'\n",
    "        module_layer.attention.output.register_forward_hook(\n",
    "            get_inputivation(layer_name_attn_output))\n",
    "        module_layer.attention.output.register_forward_hook(\n",
    "            get_activation(layer_name_attn_output))\n",
    "        \n",
    "        layer_name_self = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self'\n",
    "        module_layer.attention.self.register_forward_hook(\n",
    "            get_inputivation(layer_name_self))\n",
    "        module_layer.attention.self.register_forward_hook(\n",
    "            get_activation_multi(layer_name_self))\n",
    "\n",
    "        layer_name_value = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.value'\n",
    "        module_layer.attention.self.value.register_forward_hook(\n",
    "            get_inputivation(layer_name_value))\n",
    "        module_layer.attention.self.value.register_forward_hook(\n",
    "            get_activation(layer_name_value))\n",
    "\n",
    "        layer_name_query = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.query'\n",
    "        module_layer.attention.self.query.register_forward_hook(\n",
    "            get_inputivation(layer_name_query))\n",
    "        module_layer.attention.self.query.register_forward_hook(\n",
    "            get_activation(layer_name_query))\n",
    "\n",
    "        layer_name_key = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.key'\n",
    "        module_layer.attention.self.key.register_forward_hook(\n",
    "            get_inputivation(layer_name_key))\n",
    "        module_layer.attention.self.key.register_forward_hook(\n",
    "            get_activation(layer_name_key))\n",
    "        \n",
    "        layer_module_index += 1\n",
    "\n",
    "def gelu(x):\n",
    "    \"\"\"Implementation of the gelu activation function.\n",
    "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
    "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \"\"\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "class BertConfig(object):\n",
    "    \"\"\"Configuration class to store the configuration of a `BertModel`.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                vocab_size=32000,\n",
    "                hidden_size=768,\n",
    "                num_hidden_layers=12,\n",
    "                num_attention_heads=12,\n",
    "                intermediate_size=3072,\n",
    "                hidden_act=\"gelu\",\n",
    "                hidden_dropout_prob=0.1,\n",
    "                attention_probs_dropout_prob=0.1,\n",
    "                max_position_embeddings=512,\n",
    "                type_vocab_size=16,\n",
    "                initializer_range=0.02,\n",
    "                full_pooler=False): # this is for transformer-like BERT\n",
    "        \"\"\"Constructs BertConfig.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: Vocabulary size of `inputs_ids` in `BertModel`.\n",
    "            hidden_size: Size of the encoder layers and the pooler layer.\n",
    "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
    "            num_attention_heads: Number of attention heads for each attention layer in\n",
    "                the Transformer encoder.\n",
    "            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
    "                layer in the Transformer encoder.\n",
    "            hidden_act: The non-linear activation function (function or string) in the\n",
    "                encoder and pooler.\n",
    "            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
    "                layers in the embeddings, encoder, and pooler.\n",
    "            attention_probs_dropout_prob: The dropout ratio for the attention\n",
    "                probabilities.\n",
    "            max_position_embeddings: The maximum sequence length that this model might\n",
    "                ever be used with. Typically set this to something large just in case\n",
    "                (e.g., 512 or 1024 or 2048).\n",
    "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
    "                `BertModel`.\n",
    "            initializer_range: The sttdev of the truncated_normal_initializer for\n",
    "                initializing all weight matrices.\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.full_pooler = full_pooler\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, json_object):\n",
    "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n",
    "        config = BertConfig(vocab_size=None)\n",
    "        for (key, value) in six.iteritems(json_object):\n",
    "            config.__dict__[key] = value\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_json_file(cls, json_file):\n",
    "        \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n",
    "        with open(json_file, \"r\") as reader:\n",
    "            text = reader.read()\n",
    "        return cls.from_dict(json.loads(text))\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "    \n",
    "class BERTLayerNorm(nn.Module):\n",
    "    def __init__(self, config, variance_epsilon=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super(BERTLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(config.hidden_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(config.hidden_size))\n",
    "        self.variance_epsilon = variance_epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.gamma * x + self.beta\n",
    "\n",
    "class BERTEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTEmbeddings, self).__init__()\n",
    "        \"\"\"Construct the embedding module from word, position and token_type embeddings.\n",
    "        \"\"\"\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = BERTLayerNorm(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "    def backward_lrp(self, relevance_score):\n",
    "        # we use the whole embedding as its units\n",
    "        return relevance_score\n",
    "\n",
    "class BERTSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTSelfAttention, self).__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def transpose_for_context(self, x):\n",
    "        new_x_shape = x.size()[:2] + \\\n",
    "            (self.num_attention_heads, self.attention_head_size,)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "    def transpose_for_value(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_x_shape = x.size()[:2] + (self.all_head_size,)\n",
    "        return x.view(*new_x_shape)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        return context_layer, attention_probs\n",
    "    \n",
    "    def attention_core(self, query_layer, key_layer, value_layer, attention_mask):\n",
    "        \"\"\"\n",
    "        This is the core self-attention layer.\n",
    "        \"\"\"\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        \n",
    "        return attention_probs\n",
    "    \n",
    "    def jacobian(self, tensor_out, tensor_in, debug=False):\n",
    "        \"\"\"\n",
    "        This is super slow. You can simply write out the full\n",
    "        jacboian by hand, and it would be so much faster.\n",
    "        PyTorch team is working on a fastor impl which is still\n",
    "        in progress.\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start = time.time()\n",
    "        jacobian_full = []\n",
    "        for i in range(tensor_out.shape[2]):\n",
    "            jac_mask = torch.zeros_like(tensor_out)\n",
    "            jac_mask[:,:,i] = 1.\n",
    "            jacobian_partial = torch.autograd.grad(tensor_out, tensor_in,\n",
    "                                                   grad_outputs=jac_mask,\n",
    "                                                   retain_graph=True)[0]\n",
    "            jacobian_full.append(jacobian_partial)\n",
    "        jacobian_full = torch.stack(jacobian_full, dim=2)\n",
    "        end = time.time()\n",
    "        if debug:\n",
    "            print(jacobian_full.shape)\n",
    "            print(\"Time Elapse for 1 Jacobian Full: \", end - start)\n",
    "        return jacobian_full\n",
    "\n",
    "    def _attn_head_jacobian(self, q, k, v, attn_mask):\n",
    "        \"\"\" \n",
    "        same as jacobian above, but faster \n",
    "        referene code: \n",
    "        https://github.com/lena-voita/the-story-of-heads/blob/master/lib/layers/attn_lrp.py\n",
    "        \"\"\"\n",
    "        # input shapes: (q, k, v) - [batch_size, n_q or n_kv, dim per head]\n",
    "        # attn_head_mask: [batch_size, n_q, n_kv]\n",
    "        assert len(q.shape) == 3 and len(attn_mask.shape) == 3\n",
    "        \n",
    "        ATTN_BIAS_VALUE = -1e9\n",
    "        key_depth_per_head = float(q.shape[-1])\n",
    "        q = q / (key_depth_per_head ** 0.5)\n",
    "\n",
    "        attn_bias = ATTN_BIAS_VALUE * (1 - attn_mask)\n",
    "        logits = torch.matmul(q, k.permute(0,2,1)) + attn_bias\n",
    "        weights = nn.Softmax(dim=-1)(logits)  # [batch_size, n_q, n_kv]\n",
    "        out = torch.matmul(weights, v)  # [batch_size, n_q, dim/n_heads]\n",
    "\n",
    "        batch_size, n_kv, dim_per_head = v.shape[0], v.shape[1], v.shape[2]\n",
    "\n",
    "        diag_flat_weights = torch.einsum('ij,jqk->iqjk', \n",
    "                                         torch.eye(weights.shape[0]), weights)  # [b, n_q, b, n_kv]\n",
    "        flat_jac_v = diag_flat_weights[:, :, None, :, :, None] * \\\n",
    "                        torch.eye(dim_per_head)[None, None, :, None, None, :]\n",
    "        # ^-- shape: [batch_size, n_q, dim/h, batch_size, n_kv, dim/h]\n",
    "        # torch.Size([1, 48, 64, 1, 48, 64])\n",
    "\n",
    "        # ... just to get around this torch.tile(v[:, None], [1, out.shape[1], 1, 1])\n",
    "        jac_out_wrt_weights = torch.cat(out.shape[1]*[v[:, None]], dim=1) \n",
    "        jac_out_wrt_weights = jac_out_wrt_weights.permute([0, 1, 3, 2])\n",
    "        # ^-- [batch_size, n_q, (dim), (n_kv)]\n",
    "        \n",
    "        softmax_jac = (weights[..., None] * torch.eye(weights.shape[-1])\n",
    "                       - weights[..., None, :] * weights[..., :, None])  # <-- [batch_size, n_q, n_kv, n_kv]\n",
    "        jac_out_wrt_logits = jac_out_wrt_weights @ softmax_jac  # [batch_size, n_q, (dim), (n_kv)]\n",
    "\n",
    "        jac_out_wrt_k = jac_out_wrt_logits[..., None] * q[:, :, None, None, :]  # [b, (n_q, dim), (n_kv, dim)]\n",
    "        \n",
    "        # product axes:                    b  q  d  kv   d       b  q      d    kv d\n",
    "        jac_out_wrt_q = jac_out_wrt_logits[:, :, :, :, None] * k[:, None, None, :, :]\n",
    "        jac_out_wrt_q = jac_out_wrt_q.sum(dim=3, keepdim=True)\n",
    "        jac_out_wrt_q = jac_out_wrt_q / float(key_depth_per_head) ** 0.5\n",
    "        jac_out_wrt_q = jac_out_wrt_q * torch.eye(jac_out_wrt_q.shape[1])[None, :, None, :, None]\n",
    "\n",
    "        flat_jac_k = jac_out_wrt_k[..., None, :, :] * torch.eye(q.shape[0])[:, None, None, :, None, None]\n",
    "        flat_jac_q = jac_out_wrt_q[..., None, :, :] * torch.eye(q.shape[0])[:, None, None, :, None, None]\n",
    "        # final shape of flat_jac_{q, k}: [(batch_size, n_q, dim), (batch_size, n_kv, dim)]\n",
    "\n",
    "        return flat_jac_q, flat_jac_k, flat_jac_v\n",
    "    \n",
    "    def backward_lrp(self, relevance_score, layer_module_index, lrp_detour=\"quick\"):\n",
    "        \"\"\"\n",
    "        This is the lrp explicitily considering the attention layer.\n",
    "        \"\"\"\n",
    "\n",
    "        layer_name_value = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.value'\n",
    "        layer_name_query = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.query'\n",
    "        layer_name_key = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self.key'\n",
    "        value_in = func_inputs[layer_name_value][0]\n",
    "        value_out = func_activations[layer_name_value]\n",
    "        query_in = func_inputs[layer_name_query][0]\n",
    "        query_out = func_activations[layer_name_query]\n",
    "        key_in = func_inputs[layer_name_key][0]\n",
    "        key_out = func_activations[layer_name_key]\n",
    "        layer_name_self = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                                '.attention.self'\n",
    "        context_layer = func_activations[layer_name_self][0]\n",
    "        attention_mask = func_inputs[layer_name_self][1]\n",
    "        if lrp_detour == \"quick\":\n",
    "            # Instead of jacobian, we may estimate this using a linear layer\n",
    "            # This turns out to be a good estimate in general.\n",
    "            relevance_query = \\\n",
    "                torch.autograd.grad(context_layer, query_out, \n",
    "                                    grad_outputs=relevance_score, \n",
    "                                    retain_graph=True)[0]\n",
    "            relevance_key = \\\n",
    "                torch.autograd.grad(context_layer, key_out, \n",
    "                                    grad_outputs=relevance_score, \n",
    "                                    retain_graph=True)[0]\n",
    "            relevance_value = \\\n",
    "                torch.autograd.grad(context_layer, value_out, \n",
    "                                    grad_outputs=relevance_score, \n",
    "                                    retain_graph=True)[0]\n",
    "\n",
    "            relevance_query = backprop_lrp_fc(self.query.weight,\n",
    "                                              self.query.bias,\n",
    "                                              query_in,\n",
    "                                              relevance_query)\n",
    "            relevance_key = backprop_lrp_fc(self.key.weight,\n",
    "                                              self.key.bias,\n",
    "                                              key_in,\n",
    "                                              relevance_key)\n",
    "            relevance_value = backprop_lrp_fc(self.value.weight,\n",
    "                                              self.value.bias,\n",
    "                                              value_in,\n",
    "                                              relevance_value)\n",
    "            relevance_score = relevance_query + relevance_key + relevance_value\n",
    "        elif lrp_detour == \"jacobian\":\n",
    "            print(\"Full Jacobian can be very slow. Consider our validated quick method.\")\n",
    "            query_out_head = self.transpose_for_scores(query_out)\n",
    "            key_out_head = self.transpose_for_scores(key_out)\n",
    "            value_out_head = self.transpose_for_scores(value_out)\n",
    "            relevance_score = self.transpose_for_context(relevance_score) # [b, n_h, seq_l, h_dim]\n",
    "\n",
    "            b_n, n_h, seq_l, h_dim = query_out_head.shape[0], query_out_head.shape[1], query_out_head.shape[2], query_out_head.shape[3]\n",
    "            query_out_head_flat = query_out_head.reshape([-1, seq_l, h_dim])\n",
    "            key_out_head_flat = key_out_head.reshape([-1, seq_l, h_dim])\n",
    "            value_out_head_flat = value_out_head.reshape([-1, seq_l, h_dim])\n",
    "            relevance_score_flat = relevance_score.reshape([-1, seq_l, h_dim])\n",
    "            attention_mask_flat = torch.cat(n_h*[attention_mask], dim=1).reshape([-1, 1, seq_l])\n",
    "            \n",
    "            # flatten them to save memory\n",
    "            flat_relevence_qs = []\n",
    "            flat_relevence_ks = []\n",
    "            flat_relevence_vs = []\n",
    "            for i in range(relevance_score_flat.shape[0]):\n",
    "                flat_jac_q, flat_jac_k, flat_jac_v = \\\n",
    "                    self._attn_head_jacobian(query_out_head_flat[i, None],\n",
    "                                             key_out_head_flat[i, None],\n",
    "                                             value_out_head_flat[i, None],\n",
    "                                             attention_mask_flat[i, None])\n",
    "                output_flat = self.attention_core(query_out_head_flat[i, None], \n",
    "                                               key_out_head_flat[i, None], \n",
    "                                               value_out_head_flat[i, None], \n",
    "                                               attention_mask_flat[i, None])\n",
    "                flat_relevence_q, flat_relevence_k, flat_relevence_v = \\\n",
    "                    backprop_lrp_jacobian((flat_jac_q, flat_jac_k, flat_jac_v), \n",
    "                                          output_flat, \n",
    "                                          relevance_score_flat[i, None], \n",
    "                                          (query_out_head_flat[i, None], \n",
    "                                          key_out_head_flat[i, None], \n",
    "                                          value_out_head_flat[i, None]))\n",
    "                flat_relevence_qs.append(flat_relevence_q)\n",
    "                flat_relevence_ks.append(flat_relevence_k)\n",
    "                flat_relevence_vs.append(flat_relevence_v)\n",
    "            flat_relevence_qs = torch.stack(flat_relevence_qs, dim=0)\n",
    "            flat_relevence_ks = torch.stack(flat_relevence_ks, dim=0)\n",
    "            flat_relevence_vs = torch.stack(flat_relevence_vs, dim=0)\n",
    "            relevance_query = flat_relevence_qs.reshape(b_n, n_h, seq_l, h_dim).contiguous().permute(0,2,1,3).reshape(b_n, seq_l, -1).contiguous()\n",
    "            relevance_key = flat_relevence_ks.reshape(b_n, n_h, seq_l, h_dim).contiguous().permute(0,2,1,3).reshape(b_n, seq_l, -1).contiguous()\n",
    "            relevance_value = flat_relevence_vs.reshape(b_n, n_h, seq_l, h_dim).contiguous().permute(0,2,1,3).reshape(b_n, seq_l, -1).contiguous()\n",
    "            \n",
    "            # linear layers and we are done!\n",
    "            relevance_query = backprop_lrp_fc(self.query.weight,\n",
    "                                              self.query.bias,\n",
    "                                              query_in,\n",
    "                                              relevance_query)\n",
    "            relevance_key = backprop_lrp_fc(self.key.weight,\n",
    "                                              self.key.bias,\n",
    "                                              key_in,\n",
    "                                              relevance_key)\n",
    "            relevance_value = backprop_lrp_fc(self.value.weight,\n",
    "                                              self.value.bias,\n",
    "                                              value_in,\n",
    "                                              relevance_value)\n",
    "            relevance_score = relevance_query + relevance_key + relevance_value\n",
    "        return relevance_score\n",
    "\n",
    "class BERTSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTSelfOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = BERTLayerNorm(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "    def backward_lrp(self, relevance_score, layer_module_index):\n",
    "        # residual conection handler\n",
    "        layer_name = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                        '.attention.output'\n",
    "        output_in_input = func_inputs[layer_name][1]\n",
    "        output_out = func_activations[layer_name]\n",
    "        relevance_score_residual = \\\n",
    "            torch.autograd.grad(output_out, output_in_input, \n",
    "                                grad_outputs=relevance_score, \n",
    "                                retain_graph=True)[0]\n",
    "        # main connection\n",
    "        layer_name_dense = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                            '.attention.output.dense'\n",
    "        dense_out = func_activations[layer_name_dense]\n",
    "        relevance_score = \\\n",
    "            torch.autograd.grad(output_out, dense_out, \n",
    "                                grad_outputs=relevance_score, \n",
    "                                retain_graph=True)[0]\n",
    "        dense_in = func_inputs[layer_name_dense][0]\n",
    "        relevance_score = backprop_lrp_fc(self.dense.weight,\n",
    "                                          self.dense.bias,\n",
    "                                          dense_in,\n",
    "                                          relevance_score)\n",
    "        return relevance_score, relevance_score_residual\n",
    "\n",
    "class BERTAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTAttention, self).__init__()\n",
    "        self.self = BERTSelfAttention(config)\n",
    "        self.output = BERTSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask):\n",
    "        self_output, attention_probs = self.self(input_tensor, attention_mask)\n",
    "        attention_output = self.output(self_output, input_tensor)\n",
    "        return attention_output, attention_probs\n",
    "\n",
    "    def backward_lrp(self, relevance_score, layer_module_index):\n",
    "        relevance_score, relevance_score_residual = \\\n",
    "            self.output.backward_lrp(relevance_score, layer_module_index)\n",
    "        relevance_score = self.self.backward_lrp(relevance_score, layer_module_index)\n",
    "        # merge\n",
    "        relevance_score = relevance_score + relevance_score_residual\n",
    "        return relevance_score\n",
    "\n",
    "class BERTIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTIntermediate, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.intermediate_act_fn = gelu\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "    def backward_lrp(self, relevance_score, layer_module_index):\n",
    "        layer_name = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                        '.intermediate.dense'\n",
    "        dense_in = func_inputs[layer_name][0]\n",
    "        relevance_score = backprop_lrp_fc(self.dense.weight,\n",
    "                                          self.dense.bias,\n",
    "                                          dense_in,\n",
    "                                          relevance_score)\n",
    "        return relevance_score\n",
    "\n",
    "class BERTOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = BERTLayerNorm(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "    def backward_lrp(self, relevance_score, layer_module_index):\n",
    "        # residual conection handler\n",
    "        layer_name = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                        '.output'\n",
    "        output_in_input = func_inputs[layer_name][1]\n",
    "        output_out = func_activations[layer_name]\n",
    "        relevance_score_residual = \\\n",
    "            torch.autograd.grad(output_out, output_in_input, \n",
    "                                grad_outputs=relevance_score, \n",
    "                                retain_graph=True)[0]\n",
    "        # main connection\n",
    "        layer_name_dense = 'model.bert.encoder.' + str(layer_module_index) + \\\n",
    "                            '.output.dense'\n",
    "        dense_out = func_activations[layer_name_dense]\n",
    "        relevance_score = \\\n",
    "            torch.autograd.grad(output_out, dense_out, \n",
    "                                grad_outputs=relevance_score, \n",
    "                                retain_graph=True)[0]\n",
    "        dense_in = func_inputs[layer_name_dense][0]\n",
    "        relevance_score = backprop_lrp_fc(self.dense.weight,\n",
    "                                          self.dense.bias,\n",
    "                                          dense_in,\n",
    "                                          relevance_score)\n",
    "        return relevance_score, relevance_score_residual\n",
    "\n",
    "class BERTLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTLayer, self).__init__()\n",
    "        self.attention = BERTAttention(config)\n",
    "        self.intermediate = BERTIntermediate(config)\n",
    "        self.output = BERTOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output, attention_probs = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output, attention_probs\n",
    "\n",
    "    def backward_lrp(self, relevance_score, layer_module_index):\n",
    "        relevance_score, relevance_score_residual = self.output.backward_lrp(relevance_score, layer_module_index)\n",
    "        relevance_score = self.intermediate.backward_lrp(relevance_score, layer_module_index)\n",
    "        # merge\n",
    "        relevance_score += relevance_score_residual\n",
    "        relevance_score = self.attention.backward_lrp(relevance_score, layer_module_index)\n",
    "        return relevance_score\n",
    "\n",
    "class BERTEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTEncoder, self).__init__()\n",
    "        layer = BERTLayer(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])    \n",
    "        self.num_hidden_layers = config.num_hidden_layers\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        all_encoder_layers = []\n",
    "        all_encoder_attention_scores = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states, attention_probs = layer_module(hidden_states, attention_mask)\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "            all_encoder_attention_scores.append(attention_probs.data)\n",
    "        return all_encoder_layers, all_encoder_attention_scores\n",
    "\n",
    "    def backward_lrp(self, relevance_score):\n",
    "        # backout layer by layer from last to the first\n",
    "        layer_module_index = self.num_hidden_layers - 1\n",
    "        for layer_module in reversed(self.layer):\n",
    "            relevance_score = layer_module.backward_lrp(relevance_score, layer_module_index)\n",
    "            layer_module_index -= 1\n",
    "    \n",
    "        # These helps you to understand how each layer\n",
    "        # shift the relevance scores if any.\n",
    "        # instead of go through every layer, interrupt\n",
    "        # layer_name_self = 'model.bert.encoder.' + str(0) + \\\n",
    "        #                         '.attention.self'\n",
    "        # self_attn_in = func_inputs[layer_name_self][0]\n",
    "        # embedding_output = func_activations['model.bert.embeddings']\n",
    "        # relevance_score = torch.autograd.grad(self_attn_in, embedding_output, \n",
    "        #                                       grad_outputs=relevance_score, \n",
    "        #                                       retain_graph=True)[0]\n",
    "        return relevance_score\n",
    "\n",
    "class BERTPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERTPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states, optional_attn_mask=None):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        #return first_token_tensor\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "    def backward_lrp(self, relevance_score):\n",
    "        dense_in = func_inputs['model.bert.pooler.dense'][0]\n",
    "        relevance_score = backprop_lrp_fc(self.dense.weight,\n",
    "                                          self.dense.bias,\n",
    "                                          dense_in,\n",
    "                                          relevance_score)        \n",
    "        # we need to scatter this to all hidden states, but only first\n",
    "        # one matters!\n",
    "        pooler_in = func_inputs['model.bert.pooler'][0]\n",
    "        relevance_score_all = torch.zeros_like(pooler_in)\n",
    "        relevance_score_all[:, 0] = relevance_score\n",
    "        return relevance_score_all\n",
    "\n",
    "class BertModel(nn.Module):\n",
    "    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
    "\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "    config = modeling.BertConfig(vocab_size=32000, hidden_size=512,\n",
    "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
    "\n",
    "    model = modeling.BertModel(config=config)\n",
    "    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, config: BertConfig):\n",
    "        \"\"\"Constructor for BertModel.\n",
    "\n",
    "        Args:\n",
    "            config: `BertConfig` instance.\n",
    "        \"\"\"\n",
    "        super(BertModel, self).__init__()\n",
    "        self.embeddings = BERTEmbeddings(config)\n",
    "        self.encoder = BERTEncoder(config)\n",
    "        self.pooler = BERTPooler(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, from_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, to_seq_length, from_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.float()\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "        all_encoder_layers, all_encoder_attention_scores = self.encoder(embedding_output, extended_attention_mask)\n",
    "        sequence_output = all_encoder_layers[-1]\n",
    "        pooled_output = self.pooler(sequence_output, optional_attn_mask=attention_mask)\n",
    "        return all_encoder_layers, pooled_output, all_encoder_attention_scores, embedding_output\n",
    "\n",
    "    def backward_lrp(self, relevance_score):\n",
    "        relevance_score = self.pooler.backward_lrp(relevance_score)\n",
    "        relevance_score = self.encoder.backward_lrp(relevance_score)\n",
    "        return relevance_score\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "    config = BertConfig(vocab_size=32000, hidden_size=512,\n",
    "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
    "\n",
    "    num_labels = 2\n",
    "\n",
    "    model = BertForSequenceClassification(config, num_labels)\n",
    "    logits = model(input_ids, token_type_ids, input_mask)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, config, num_labels, init_weight=True, init_lrp=False):\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "        if init_weight:\n",
    "            print(\"init_weight = True\")\n",
    "            def init_weights(module):\n",
    "                if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "                    module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                elif isinstance(module, BERTLayerNorm):\n",
    "                    module.beta.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                    module.gamma.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    module.bias.data.zero_()\n",
    "            self.apply(init_weights)\n",
    "\n",
    "        if init_lrp:\n",
    "            print(\"init_lrp = True\")\n",
    "            init_hooks_lrp(self)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, seq_lens,\n",
    "                device=None, labels=None):\n",
    "        _, pooled_output, all_encoder_attention_scores, embedding_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits, all_encoder_attention_scores, embedding_output\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def backward_gradient(self, sensitivity_grads):\n",
    "        classifier_out = func_activations['model.classifier']\n",
    "        embedding_output = func_activations['model.bert.embeddings']\n",
    "        sensitivity_grads = torch.autograd.grad(classifier_out, embedding_output, \n",
    "                                                grad_outputs=sensitivity_grads, \n",
    "                                                retain_graph=True)[0]\n",
    "        return sensitivity_grads\n",
    "    \n",
    "    def backward_gradient_input(self, sensitivity_grads):\n",
    "        classifier_out = func_activations['model.classifier']\n",
    "        embedding_output = func_activations['model.bert.embeddings']\n",
    "        sensitivity_grads = torch.autograd.grad(classifier_out, embedding_output, \n",
    "                                                grad_outputs=sensitivity_grads, \n",
    "                                                retain_graph=True)[0]\n",
    "        return sensitivity_grads * embedding_output\n",
    "\n",
    "    def backward_lrp(self, relevance_score):\n",
    "        classifier_in = func_inputs['model.classifier'][0]\n",
    "        classifier_out = func_activations['model.classifier']\n",
    "        relevance_score = backprop_lrp_fc(self.classifier.weight,\n",
    "                                          self.classifier.bias,\n",
    "                                          classifier_in,\n",
    "                                          relevance_score)\n",
    "        relevance_score = self.bert.backward_lrp(relevance_score)\n",
    "        return relevance_score\n",
    "    \n",
    "    def backward_lat(self, input_ids, attention_probs):\n",
    "        \n",
    "        # backing out using the quasi-attention\n",
    "        attention_scores = torch.zeros_like(input_ids, dtype=torch.float)\n",
    "        # we need to distribution the attention on CLS to each head\n",
    "        # here, we use grad to do this\n",
    "        attention_scores[:,0] = 1.0\n",
    "        attention_scores = torch.stack(12 * [attention_scores], dim=1).unsqueeze(dim=2)\n",
    "\n",
    "        for i in reversed(range(12)):\n",
    "            attention_scores = torch.matmul(attention_scores, attention_probs[i])\n",
    "        \n",
    "        attention_scores = attention_scores.sum(dim=1).squeeze(dim=1).unsqueeze(dim=-1).data\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_setups(vocab_file, bert_config_file,\n",
    "                        init_checkpoint,\n",
    "                        label_list, \n",
    "                        num_train_steps,\n",
    "                        do_lower_case=True, \n",
    "                        learning_rate=2e-5,\n",
    "                        warmup_proportion=0.1,\n",
    "                        init_lrp=False):\n",
    "    logger.info(\"model = BERT\")\n",
    "    if bert_config_file is not None:\n",
    "        bert_config = BertConfig.from_json_file(bert_config_file)\n",
    "    else:\n",
    "        # default?\n",
    "        bert_config = BertConfig(\n",
    "            hidden_size=768,\n",
    "            num_hidden_layers=12,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072,\n",
    "            hidden_act=\"gelu\",\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=512,\n",
    "            type_vocab_size=2,\n",
    "            initializer_range=0.02\n",
    "        )\n",
    "    logger.info(\"*** Model Config ***\")\n",
    "    logger.info(bert_config.to_json_string())\n",
    "    tokenizer = FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case, pretrain=False)\n",
    "    # overwrite the vocab size to be exact. this also save space incase\n",
    "    # vocab size is shrinked.\n",
    "    bert_config.vocab_size = len(tokenizer.vocab)\n",
    "    # model and optimizer\n",
    "    model = BertForSequenceClassification(bert_config, len(label_list), init_lrp=init_lrp)\n",
    "    if init_checkpoint is None:\n",
    "        err_msg = \"Error: model have to be based on a pretrained model\"\n",
    "        logger.warning(err_msg)\n",
    "        raise Exception(err_msg)\n",
    "    \n",
    "    # checkpoint should be used only for generated model during training\n",
    "    if \"checkpoint\" in init_checkpoint:\n",
    "        # we need to add handling logic specially for parallel gpu trainign\n",
    "        state_dict = torch.load(init_checkpoint, map_location='cpu')\n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            if k.startswith('module.'):\n",
    "                name = k[7:] # remove 'module.' of dataparallel\n",
    "                new_state_dict[name]=v\n",
    "            else:\n",
    "                new_state_dict[k]=v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        logger.info(\"retraining with saved model.\")\n",
    "        model.bert.load_state_dict(torch.load(init_checkpoint, map_location='cpu'))\n",
    "\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() \n",
    "            if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() \n",
    "            if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    optimizer = BERTAdam(optimizer_parameters,\n",
    "                        lr=learning_rate,\n",
    "                        warmup=warmup_proportion,\n",
    "                        t_total=num_train_steps)\n",
    "    return model, tokenizer, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 14:15:48 - INFO - run_classifier -   gpu is out of the picture, let us use CPU\n"
     ]
    }
   ],
   "source": [
    "# Note that this notebook only supports single GPU evaluation\n",
    "# which is sufficient for most of tasks by using lower batch size.\n",
    "IS_CUDA = False\n",
    "if IS_CUDA:\n",
    "    CUDA_DEVICE = \"cuda:0\"\n",
    "    device = torch.device(CUDA_DEVICE)\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    logger.info(\"device %s in total n_gpu %d distributed training\", device, n_gpu)\n",
    "else:\n",
    "    # bad luck, we are on CPU now!\n",
    "    logger.info(\"gpu is out of the picture, let us use CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "def inverse_mapping(vocab_dict):\n",
    "    inverse_vocab_dict = {}\n",
    "    for k, v in vocab_dict.items():\n",
    "        inverse_vocab_dict[v] = k\n",
    "    return inverse_vocab_dict\n",
    "\n",
    "def translate(token_ids, vocab):\n",
    "    tokens = []\n",
    "    for _id in token_ids.tolist():\n",
    "        tokens.append(vocab[_id])\n",
    "    return tokens\n",
    "\n",
    "def heatmap_viz(token_grad, vmin=0, cmap=\"Blues\"):\n",
    "    scores = [tu[1] for tu in token_grad]\n",
    "    tokens = [tu[0] for tu in token_grad]\n",
    "    fig, ax = plt.subplots(figsize=(10,1))\n",
    "    ax = sns.heatmap([scores], cmap=cmap, xticklabels=tokens, yticklabels=False,\n",
    "                     cbar_kws=dict(shrink=1, aspect=4, ), linewidths=0.8)\n",
    "    ax.set_xticklabels(tokens, size = 18)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "def evaluate_with_hooks(test_dataloader, model, device, label_list):\n",
    "\n",
    "    # we did not exclude gradients, for attribution methods\n",
    "    model.eval() # this line will deactivate dropouts\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    nb_test_steps, nb_test_examples = 0, 0\n",
    "    pred_logits = []\n",
    "    actual = []\n",
    "\n",
    "    gs_scores = []\n",
    "    gi_scores = []\n",
    "    lrp_scores = []\n",
    "    lat_scores = []\n",
    "\n",
    "    inputs_ids = []\n",
    "    seqs_lens = []\n",
    "\n",
    "    # we don't need gradient in this case.\n",
    "    for _, batch in enumerate(tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lens = batch\n",
    "        # truncate to save space and computing resource\n",
    "        max_seq_lens = max(seq_lens)[0]\n",
    "        input_ids = input_ids[:,:max_seq_lens]\n",
    "        input_mask = input_mask[:,:max_seq_lens]\n",
    "        segment_ids = segment_ids[:,:max_seq_lens]\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        seq_lens = seq_lens.to(device)\n",
    "\n",
    "        # intentially with gradient\n",
    "        tmp_test_loss, logits_raw, all_encoder_attention_scores, embedding_output = \\\n",
    "            model(input_ids, segment_ids, input_mask, seq_lens,\n",
    "                    device=device, labels=label_ids)\n",
    "        logits_t = F.softmax(logits_raw, dim=-1)\n",
    "\n",
    "        logits = logits_t.detach().cpu().numpy()\n",
    "        pred_logits.append(logits)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        actual.append(label_ids)\n",
    "        outputs = np.argmax(logits, axis=1)\n",
    "        tmp_test_accuracy=np.sum(outputs == label_ids)\n",
    "        \n",
    "        sensitivity_class = len(label_list) - 1\n",
    "\n",
    "        # GS\n",
    "        gs_score = torch.zeros(logits_t.shape)\n",
    "        gs_score[:, sensitivity_class] = 1.0\n",
    "        gs_score = logits_raw*gs_score\n",
    "        gs_score = model.backward_gradient(gs_score)\n",
    "        gs_score = torch.norm(gs_score, dim=-1)*torch.norm(gs_score, dim=-1)\n",
    "        gs_scores.append(gs_score)\n",
    "        \n",
    "        # GI\n",
    "        gi_score = torch.zeros(logits_t.shape)\n",
    "        gi_score[:, sensitivity_class] = 1.0\n",
    "        gi_score = logits_raw*gi_score\n",
    "        gi_score = model.backward_gradient_input(gi_score)\n",
    "        gi_score = torch.norm(gi_score, dim=-1)*torch.norm(gi_score, dim=-1)\n",
    "        gi_scores.append(gi_score)\n",
    "\n",
    "        \n",
    "        # lrp\n",
    "        Rout_mask = torch.zeros((input_ids.shape[0], len(label_list))).to(device)\n",
    "        Rout_mask[:, sensitivity_class] = 1.0\n",
    "        relevance_score = logits_raw*Rout_mask\n",
    "        lrp_score = model.backward_lrp(relevance_score)\n",
    "        lrp_score = lrp_score.cpu().detach().data\n",
    "        lrp_score = torch.abs(lrp_score).sum(dim=-1)\n",
    "        lrp_scores.append(lrp_score)\n",
    "\n",
    "        # lat\n",
    "        attention_scores = model.backward_lat(input_ids, all_encoder_attention_scores)\n",
    "        lat_scores.append(attention_scores.sum(dim=-1))\n",
    "\n",
    "        # other meta-data\n",
    "        input_ids = input_ids.cpu().data\n",
    "        seq_lens = seq_lens.cpu().data\n",
    "        inputs_ids.append(input_ids)\n",
    "        seqs_lens.append(seq_lens)\n",
    "\n",
    "        test_loss += tmp_test_loss.mean().item()\n",
    "        test_accuracy += tmp_test_accuracy\n",
    "\n",
    "        nb_test_examples += input_ids.size(0)\n",
    "        nb_test_steps += 1\n",
    "\n",
    "    test_loss = test_loss / nb_test_steps\n",
    "    test_accuracy = test_accuracy / nb_test_examples\n",
    "\n",
    "    result = collections.OrderedDict()\n",
    "    result = {'test_loss': test_loss,\n",
    "                str(len(label_list))+ '-class test_accuracy': test_accuracy}\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in result.keys():\n",
    "        logger.info(\"  %s = %s\\n\", key, str(result[key]))\n",
    "    # get predictions needed for evaluation\n",
    "    pred_logits = np.concatenate(pred_logits, axis=0)\n",
    "    actual = np.concatenate(actual, axis=0)\n",
    "    pred_label = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    attribution_scores_state_dict = dict()\n",
    "    attribution_scores_state_dict[\"inputs_ids\"] = inputs_ids\n",
    "    attribution_scores_state_dict[\"seqs_lens\"] = seqs_lens\n",
    "    attribution_scores_state_dict[\"gs_scores\"] = gs_scores\n",
    "    attribution_scores_state_dict[\"gi_scores\"] = gi_scores\n",
    "    attribution_scores_state_dict[\"lrp_scores\"] = lrp_scores\n",
    "    attribution_scores_state_dict[\"lat_scores\"] = lat_scores\n",
    "\n",
    "    logger.info(\"***** Finish Attribution Backouts *****\")\n",
    "    return attribution_scores_state_dict\n",
    "\n",
    "def analysis_task(task_name, device, sentence_limit=5000):\n",
    "    \"\"\"\n",
    "    We need to set a limit otherwise it takes too long!\n",
    "    \"\"\"\n",
    "    TASK_NAME = task_name\n",
    "    lrp_data_dir = \"../../results\"\n",
    "    vocab_data_dir = \"../../models/BERT-Google/vocab.txt\"\n",
    "    DATA_DIR = \"../../datasets/\" + TASK_NAME + \"/\"\n",
    "\n",
    "    # \"../../data/uncased_L-12_H-768_A-12/\" is for the default BERT-base pretrain\n",
    "    BERT_PATH = \"../../models/BERT-Google/\"\n",
    "    MODEL_PATH = \"../../results/\" + TASK_NAME + \"/best_checkpoint.bin\"\n",
    "    EVAL_BATCH_SIZE = 24 # you can tune this down depends on GPU you have.\n",
    "\n",
    "    # This loads the task processor for you.\n",
    "    processors = {\n",
    "        \"SST5\": SST5_Processor,\n",
    "        \"SemEval\" : SemEval_Processor,\n",
    "        \"IMDb\" : IMDb_Processor,\n",
    "        \"Yelp5\" : Yelp5_Processor\n",
    "    }\n",
    "\n",
    "    processor = processors[TASK_NAME]()\n",
    "    label_list = processor.get_labels()\n",
    "    \n",
    "    model, tokenizer, optimizer = \\\n",
    "        load_model_setups(vocab_file=BERT_PATH + \"vocab.txt\",\n",
    "                           bert_config_file=BERT_PATH + \"bert_config.json\",\n",
    "                           init_checkpoint=MODEL_PATH,\n",
    "                           label_list=label_list,\n",
    "                           num_train_steps=20,\n",
    "                           do_lower_case=True,\n",
    "                           # below is not required for eval\n",
    "                           learning_rate=2e-5,\n",
    "                           warmup_proportion=0.1,\n",
    "                           init_lrp=True)\n",
    "    model = model.to(device) # send the model to device\n",
    "    \n",
    "    test_examples = processor.get_test_examples(DATA_DIR, sentence_limit=sentence_limit)\n",
    "    test_features = \\\n",
    "        convert_examples_to_features(\n",
    "            test_examples,\n",
    "            label_list,\n",
    "            128,\n",
    "            tokenizer)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
    "    all_seq_len = torch.tensor([[f.seq_len] for f in test_features], dtype=torch.long)\n",
    "\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                              all_label_ids, all_seq_len)\n",
    "\n",
    "    test_dataloader = DataLoader(test_data, batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    score_dict = evaluate_with_hooks(test_dataloader, model, device, label_list)\n",
    "    \n",
    "    return score_dict\n",
    "\n",
    "def find_common_vocab(dict_list):\n",
    "    assert len(dict_list) > 0\n",
    "    common_vocab = set(dict_list[0].keys())\n",
    "    for i in range(1, len(dict_list)):\n",
    "        common_vocab = common_vocab.intersection(set(dict_list[i].keys()))\n",
    "    return common_vocab\n",
    "\n",
    "def subset_score(dict_list):\n",
    "    common_vocab = find_common_vocab(dict_list)\n",
    "    per_word_score = []\n",
    "    for word in common_vocab:\n",
    "        word_score = []\n",
    "        for d in dict_list:\n",
    "            word_score.append(d[word])\n",
    "        per_word_score.append(word_score)\n",
    "    return np.transpose(np.array(per_word_score)) \n",
    "\n",
    "def load_attribution_scores(vocab_data_dir, inputs_ids, seqs_lens, raw_attribution_scores, min_freq=5, \n",
    "                            consider_speicial_tokens=False, normalized=True, min_length=10):\n",
    "    vocab = inverse_mapping(load_vocab(vocab_data_dir, pretrain=False))\n",
    "    word_lrp = {}\n",
    "    word_lrp_list = []\n",
    "    sentence_lrp = []\n",
    "    for batch_idx in range(len(inputs_ids)):\n",
    "        for seq_idx in range(inputs_ids[batch_idx].shape[0]):\n",
    "            seq_len = seqs_lens[batch_idx][seq_idx].tolist()[0]\n",
    "            if consider_speicial_tokens:\n",
    "                tokens = translate(inputs_ids[batch_idx][seq_idx], vocab)[:seq_len]\n",
    "                attribution_scores = raw_attribution_scores[batch_idx][seq_idx][:seq_len]\n",
    "            else:\n",
    "                tokens = translate(inputs_ids[batch_idx][seq_idx], vocab)[:seq_len][1:-1]\n",
    "                attribution_scores = raw_attribution_scores[batch_idx][seq_idx][:seq_len][1:-1] \n",
    "            if normalized:\n",
    "                # sentence_attribution_scores = F.softmax(torch.abs(attribution_scores), dim=-1).tolist()\n",
    "                sentence_max = torch.max(torch.abs(attribution_scores), dim=-1)[0]\n",
    "                sentence_attribution_scores = \\\n",
    "                    (torch.abs(attribution_scores)/sentence_max).tolist()\n",
    "            else:\n",
    "                sentence_attribution_scores = attribution_scores.tolist()\n",
    "            if len(tokens) >= min_length:\n",
    "                assert(len(tokens) == len(sentence_attribution_scores))\n",
    "                s_lrp = list(zip(tokens, sentence_attribution_scores))\n",
    "                sentence_lrp.append(s_lrp)\n",
    "                for i in range(len(s_lrp)):\n",
    "                    token = s_lrp[i][0]\n",
    "                    score = s_lrp[i][1]\n",
    "                    word_lrp_list.append((token, score))\n",
    "                    if token in word_lrp.keys():\n",
    "                        word_lrp[token].append(score)\n",
    "                    else:\n",
    "                        word_lrp[token] = [score]\n",
    "\n",
    "    filter_word_lrp = {}\n",
    "    for k, v in word_lrp.items():\n",
    "        if len(v) > min_freq:\n",
    "            filter_word_lrp[k] = sum(v)*1.0/len(v)\n",
    "    filter_word_lrp = [(k, v) for k, v in filter_word_lrp.items()] \n",
    "    filter_word_lrp.sort(key = lambda x: x[1], reverse=True)  \n",
    "    word_lrp_list.sort(key = lambda x: x[1], reverse=True)\n",
    "    return filter_word_lrp, word_lrp_list, sentence_lrp\n",
    "\n",
    "def load_attribution_meta(vocab_data_dir, dataset_dict):\n",
    "    attribution_meta = {}\n",
    "    for item in [\"gs_scores\", \"gi_scores\", \\\n",
    "                 \"lrp_scores\", \"lat_scores\"]:\n",
    "        filtered_word_rank, raw_word_rank, sentence_revelance_score = \\\n",
    "            load_attribution_scores(vocab_data_dir,\n",
    "                                    dataset_dict[\"inputs_ids\"], \n",
    "                                    dataset_dict[\"seqs_lens\"],\n",
    "                                    dataset_dict[item])\n",
    "        attribution_meta[item] = {\"filtered_word_rank\": filtered_word_rank, \n",
    "                                  \"raw_word_rank\": raw_word_rank, \n",
    "                                  \"sentence_revelance_score\": sentence_revelance_score}\n",
    "    return attribution_meta\n",
    "\n",
    "def plot_sentence_heatmaps(attribution_meta, n_sample=1):\n",
    "    total_n = len(attribution_meta[\"gs_scores\"][\"sentence_revelance_score\"])\n",
    "    random_n = random.randint(0, total_n)\n",
    "    sentence_heatmap_dict = dict()\n",
    "    for item in [\"gs_scores\", \"gi_scores\", \\\n",
    "                 \"lrp_scores\", \"lat_scores\"]:\n",
    "        sentence_heatmap_dict[item] = attribution_meta[item][\"sentence_revelance_score\"][random_n]\n",
    "        heatmap_viz(sentence_heatmap_dict[item], vmin=0)\n",
    "\n",
    "def print_topk_words(attribution_meta, k=30, filtered=True):\n",
    "    \"\"\"\n",
    "    print top k words for a dataset\n",
    "    \"\"\"\n",
    "    from tabulate import tabulate\n",
    "    words = []\n",
    "    words_neg = []\n",
    "    index = 0\n",
    "    for i in range(0, k):\n",
    "        item_words = []\n",
    "        item_words_neg = []\n",
    "        for item in [\"gs_scores\", \"gi_scores\", \\\n",
    "                     \"lrp_scores\", \"lat_scores\"]:\n",
    "            \n",
    "            word_rank = None\n",
    "            if filtered:\n",
    "                word_rank = attribution_meta[item][\"filtered_word_rank\"]\n",
    "            else:\n",
    "                word_rank = attribution_meta[item][\"raw_word_rank\"]\n",
    "            item_words.append((word_rank[i][0], round(word_rank[i][1],5) ) )\n",
    "            item_words_neg.append(( word_rank[-(i+1)][0], round(word_rank[-(i+1)][1],5) ))\n",
    "\n",
    "        words.append(item_words)\n",
    "        words_neg.append(item_words_neg) # reversed ranking\n",
    "\n",
    "    print(tabulate(words, headers=[\"gs_scores\", \"gi_scores\", \"lrp_scores\", \"lat_scores\"]))\n",
    "    print(\"***\")\n",
    "    print(tabulate(words_neg, headers=[\"gs_scores\", \"gi_scores\", \"lrp_scores\", \"lat_scores\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3.2.1 SST-5 Word Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 13:57:12 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 13:57:12 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 13:57:12 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 292/2001 [00:00<00:00, 2917.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 2000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= no movement , no yuks , not much of anything .\n",
      "text_b= None\n",
      "label= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2001/2001 [00:00<00:00, 2750.74it/s]\n",
      "Iteration: 100%|██████████| 84/84 [02:59<00:00,  2.14s/it]\n",
      "12/29/2020 14:00:14 - INFO - run_classifier -   ***** Eval results *****\n",
      "12/29/2020 14:00:14 - INFO - run_classifier -     test_loss = 1.0573235069002425\n",
      "\n",
      "12/29/2020 14:00:14 - INFO - run_classifier -     5-class test_accuracy = 0.5727136431784108\n",
      "\n",
      "12/29/2020 14:00:14 - INFO - run_classifier -   ***** Finish Attribution Backouts *****\n"
     ]
    }
   ],
   "source": [
    "sst5_dict = analysis_task(\"SST5\", device, sentence_limit=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_attribution_meta = load_attribution_meta(vocab_data_dir, sst5_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_scores                gi_scores                lrp_scores               lat_scores\n",
      "-----------------------  -----------------------  -----------------------  ------------------------\n",
      "('fails', 0.90606)       ('fails', 0.92061)       ('refreshing', 0.9554)   ('.', 0.97692)\n",
      "('worst', 0.83186)       ('##unk', 0.86002)       ('##unk', 0.9017)        ('?', 0.84178)\n",
      "('refreshing', 0.81961)  ('##ional', 0.84693)     ('hilarious', 0.89296)   ('!', 0.73134)\n",
      "('##ional', 0.81286)     ('worst', 0.83212)       ('compelling', 0.8779)   ('in', 0.70923)\n",
      "('##unk', 0.79289)       ('refreshing', 0.82142)  ('worthy', 0.86397)      ('repetitive', 0.70222)\n",
      "('weak', 0.76338)        ('weak', 0.77103)        ('earnest', 0.86332)     (',', 0.65481)\n",
      "('dumb', 0.75861)        ('dumb', 0.76582)        ('fails', 0.86016)       ('fascinating', 0.65022)\n",
      "('compelling', 0.74994)  ('rare', 0.74472)        ('dumb', 0.86006)        ('indeed', 0.63482)\n",
      "('creepy', 0.7435)       ('enjoyable', 0.74252)   ('drag', 0.85731)        ('interesting', 0.62241)\n",
      "('silly', 0.74155)       ('miss', 0.73668)        ('enjoyable', 0.8545)    ('beautifully', 0.6216)\n",
      "('rare', 0.74088)        ('compelling', 0.73621)  ('gag', 0.85108)         ('remember', 0.61808)\n",
      "('profound', 0.73761)    ('creepy', 0.72161)      ('creepy', 0.85005)      ('ultimately', 0.61194)\n",
      "('enjoyable', 0.72713)   ('gag', 0.71479)         ('obvious', 0.84438)     ('although', 0.60127)\n",
      "('bland', 0.71638)       ('bland', 0.71184)       ('mess', 0.84414)        ('barely', 0.58847)\n",
      "('intriguing', 0.70806)  ('drag', 0.70409)        ('weak', 0.84282)        ('whether', 0.58623)\n",
      "('perfect', 0.70351)     ('lacks', 0.70203)       ('nonsense', 0.84272)    ('creepy', 0.57978)\n",
      "('boring', 0.69856)      ('perfect', 0.70006)     ('bland', 0.84142)       ('worst', 0.5765)\n",
      "('lacks', 0.69425)       ('profound', 0.6991)     ('worse', 0.83344)       ('lacks', 0.5758)\n",
      "('miss', 0.69306)        ('worse', 0.6945)        ('worst', 0.83253)       ('genuine', 0.57456)\n",
      "('problem', 0.69048)     ('boring', 0.68701)      ('cute', 0.81769)        ('to', 0.56971)\n",
      "('drag', 0.68457)        ('earnest', 0.68479)     ('rare', 0.8145)         ('hilarious', 0.56727)\n",
      "('ponder', 0.68276)      ('mess', 0.68433)        ('lacks', 0.81358)       ('disturbing', 0.56639)\n",
      "('laughs', 0.68067)      ('ponder', 0.68067)      ('problem', 0.81285)     ('impressive', 0.56531)\n",
      "('mess', 0.67352)        ('honest', 0.67915)      ('terrific', 0.81206)    ('there', 0.56228)\n",
      "('decent', 0.65967)      ('problem', 0.67888)     ('intriguing', 0.81197)  ('possible', 0.56137)\n",
      "('earnest', 0.65642)     ('disturbing', 0.67836)  ('neither', 0.80583)     ('manages', 0.55952)\n",
      "('gag', 0.65482)         ('precious', 0.67693)    ('perfect', 0.80257)     ('perhaps', 0.55925)\n",
      "('precious', 0.64535)    ('decent', 0.66708)      ('slick', 0.79357)       ('bizarre', 0.55851)\n",
      "('worse', 0.64436)       ('laughs', 0.66584)      ('silly', 0.7894)        ('intriguing', 0.55751)\n",
      "('honest', 0.64102)      ('##lib', 0.65459)       ('dull', 0.78863)        ('amusing', 0.55715)\n",
      "***\n",
      "gs_scores             gi_scores             lrp_scores            lat_scores\n",
      "--------------------  --------------------  --------------------  -------------------\n",
      "('##a', 0.01852)      ('##a', 0.01134)      ('##a', 0.14943)      ('##ion', 0.2635)\n",
      "('michael', 0.02077)  (\"'\", 0.01419)        (\"'\", 0.15161)        ('##pp', 0.27988)\n",
      "(\"'\", 0.02299)        ('the', 0.01561)      ('s', 0.15887)        ('hip', 0.28579)\n",
      "('##i', 0.02746)      ('michael', 0.01595)  ('female', 0.1592)    ('fu', 0.28805)\n",
      "('s', 0.02803)        ('of', 0.01708)       ('ve', 0.17065)       ('##n', 0.29043)\n",
      "('female', 0.02805)   ('and', 0.018)        ('##k', 0.1733)       ('##th', 0.29136)\n",
      "('##z', 0.02808)      ('##i', 0.0184)       ('##x', 0.17407)      ('##ic', 0.29188)\n",
      "('ka', 0.02869)       (',', 0.01908)        ('ka', 0.1776)        ('ga', 0.2934)\n",
      "('##m', 0.03092)      ('##s', 0.0191)       ('the', 0.17878)      ('el', 0.29368)\n",
      "('##s', 0.03241)      ('.', 0.01914)        ('of', 0.18)          ('tu', 0.29434)\n",
      "('##b', 0.03275)      ('s', 0.02014)        ('##s', 0.18092)      ('##ct', 0.29586)\n",
      "('the', 0.03299)      ('female', 0.02045)   ('##i', 0.18151)      ('##rb', 0.2972)\n",
      "('an', 0.03427)       ('a', 0.02085)        ('their', 0.18433)    ('##x', 0.29741)\n",
      "('it', 0.03466)       ('##z', 0.02266)      ('an', 0.1846)        ('##t', 0.29772)\n",
      "('ve', 0.03523)       ('ka', 0.02302)       ('per', 0.18607)      ('##nt', 0.29793)\n",
      "('of', 0.03533)       ('to', 0.02361)       ('##z', 0.18758)      ('##der', 0.29797)\n",
      "('##ie', 0.03601)     ('it', 0.02414)       ('a', 0.18913)        ('female', 0.29829)\n",
      "('##x', 0.03622)      ('in', 0.02507)       ('it', 0.18951)       ('li', 0.2986)\n",
      "('their', 0.03629)    ('an', 0.02564)       ('##b', 0.19054)      ('##no', 0.29924)\n",
      "('a', 0.03632)        ('his', 0.02667)      ('re', 0.19471)       ('##ni', 0.30063)\n",
      "('o', 0.03652)        ('she', 0.02686)      ('she', 0.19537)      ('make', 0.30151)\n",
      "('##ti', 0.03663)     ('##b', 0.02733)      ('to', 0.19555)       ('su', 0.30363)\n",
      "('post', 0.03699)     ('##m', 0.02761)      ('co', 0.19859)       ('app', 0.30371)\n",
      "('sand', 0.03735)     ('their', 0.02796)    ('michael', 0.19938)  ('pl', 0.30396)\n",
      "('women', 0.03768)    ('he', 0.02899)       ('his', 0.20007)      ('cu', 0.30421)\n",
      "('ni', 0.03881)       ('##ie', 0.02903)     ('##l', 0.20134)      ('ad', 0.30455)\n",
      "('co', 0.03932)       ('on', 0.02922)       ('they', 0.20199)     ('##ce', 0.30738)\n",
      "('##l', 0.0394)       ('##l', 0.02961)      ('post', 0.20211)     ('sci', 0.30859)\n",
      "('per', 0.04066)      ('four', 0.03093)     ('##ti', 0.20393)     ('##al', 0.30892)\n",
      "('mr', 0.04075)       ('##x', 0.0311)       ('o', 0.20533)        ('wo', 0.30945)\n"
     ]
    }
   ],
   "source": [
    "print_topk_words(sst5_attribution_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sentence_heatmaps(sst5_attribution_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 3.2.2 Word deletion experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "def random_drop(input_ids_to_copy, seq_lens, k=1):\n",
    "    input_ids = input_ids_to_copy.clone()\n",
    "    for b in range(input_ids.shape[0]):\n",
    "        if k > seq_lens[b][0]-2:\n",
    "            input_ids[b] = 0. # zero out all of them\n",
    "        else:\n",
    "            zero_out_idx = random.sample(range(1, seq_lens[b][0]), k)\n",
    "            for idx in zero_out_idx:\n",
    "                input_ids[b][idx] = 0.\n",
    "    return input_ids\n",
    "\n",
    "def topk_drop(input_ids_to_copy, scores, new_seq_lens, k=1):\n",
    "    input_ids = input_ids_to_copy.clone()\n",
    "    for b in range(input_ids.shape[0]):\n",
    "        if k > new_seq_lens[b][0]-2:\n",
    "            input_ids[b] = 0.\n",
    "        else:\n",
    "            _, zero_out_idx = torch.topk(scores[b][:new_seq_lens[b]][1:-1], k, dim=-1)\n",
    "            zero_out_idx = zero_out_idx + 1\n",
    "            for idx in zero_out_idx:\n",
    "                input_ids[b][idx] = 0.\n",
    "    return input_ids\n",
    "\n",
    "def sentence_filter(seq_lens, min_len=0):\n",
    "    sel_idx = []\n",
    "    for b in range(seq_lens.shape[0]):\n",
    "        if seq_lens[b][0] >= min_len:\n",
    "            sel_idx.append(b)\n",
    "    return sel_idx\n",
    "\n",
    "def evaluate_with_word_deletion(test_dataloader, model, device, label_list, \n",
    "                                k=0, del_type=\"gi\", \n",
    "                                original_correct=True,\n",
    "                                min_len=10):\n",
    "\n",
    "    # we did not exclude gradients, for attribution methods\n",
    "    model.eval() # this line will deactivate dropouts\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    nb_test_steps, nb_test_examples = 0, 0\n",
    "    pred_logits = []\n",
    "    actual = []\n",
    "\n",
    "    inputs_ids = []\n",
    "    seqs_lens = []\n",
    "    \n",
    "    k_test_accuracy = [0.0]*k\n",
    "\n",
    "    # we don't need gradient in this case.\n",
    "    for _, batch in enumerate(tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "        k_logits = []\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lens = batch\n",
    "        # truncate to save space and computing resource\n",
    "        max_seq_lens = max(seq_lens)[0]\n",
    "        input_ids = input_ids[:,:max_seq_lens]\n",
    "        input_mask = input_mask[:,:max_seq_lens]\n",
    "        segment_ids = segment_ids[:,:max_seq_lens]\n",
    "        \n",
    "        sel_idx = sentence_filter(seq_lens, min_len=min_len)\n",
    "        \n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        seq_lens = seq_lens.to(device)\n",
    "\n",
    "        input_ids = input_ids[sel_idx]\n",
    "        input_mask = input_mask[sel_idx]\n",
    "        segment_ids = segment_ids[sel_idx]\n",
    "        label_ids = label_ids[sel_idx]\n",
    "        seq_lens = seq_lens[sel_idx]\n",
    "        \n",
    "        sensitivity_class = len(label_list) - 1\n",
    "        \n",
    "        tmp_test_loss, logits, all_encoder_attention_scores, embedding_output = \\\n",
    "            model(input_ids, segment_ids, input_mask, seq_lens,\n",
    "                    device=device, labels=label_ids)\n",
    "        logits_raw = F.softmax(logits, dim=-1)\n",
    "        logits = logits_raw.detach().cpu().numpy()\n",
    "        label_ids_raw = label_ids.to('cpu').numpy()\n",
    "        outputs = np.argmax(logits, axis=1)\n",
    "        tmp_idx_correct = outputs == label_ids_raw\n",
    "        tmp_idx_correct = tmp_idx_correct.nonzero()[0]\n",
    "        tmp_idx_wrong = outputs != label_ids_raw\n",
    "        tmp_idx_wrong = tmp_idx_wrong.nonzero()[0]\n",
    "\n",
    "        if original_correct:\n",
    "            # select only those that correct\n",
    "            new_input_ids = input_ids[tmp_idx_correct]\n",
    "            new_segment_ids = segment_ids[tmp_idx_correct]\n",
    "            new_input_mask = input_mask[tmp_idx_correct]\n",
    "            new_seq_lens = seq_lens[tmp_idx_correct]\n",
    "            new_label_ids = label_ids[tmp_idx_correct]\n",
    "        else:\n",
    "            # select only those that are wrong\n",
    "            new_input_ids = input_ids[tmp_idx_wrong]\n",
    "            new_segment_ids = segment_ids[tmp_idx_wrong]\n",
    "            new_input_mask = input_mask[tmp_idx_wrong]\n",
    "            new_seq_lens = seq_lens[tmp_idx_wrong]\n",
    "            new_label_ids = label_ids[tmp_idx_wrong]\n",
    "            \n",
    "        # corner case handling, if this batch contains no examples, we bypass\n",
    "        if new_input_ids.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        if k == 0: # no need to drop\n",
    "            tmp_test_loss, logits, _, _ = \\\n",
    "                model(new_input_ids, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                        device=device, labels=new_label_ids)\n",
    "        else:\n",
    "            if del_type == \"random\":\n",
    "                # Random dropouts\n",
    "                for k_i in range(0, k):\n",
    "                    new_input_ids_curr = random_drop(new_input_ids, new_seq_lens, k=k_i+1)\n",
    "                    tmp_test_loss, logits, _, _ = \\\n",
    "                        model(new_input_ids_curr, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                                device=device, labels=new_label_ids)\n",
    "                    k_logits.append(logits)\n",
    "            elif del_type == \"gs\":\n",
    "                # GS dropouts\n",
    "                gs_score = torch.zeros(logits.shape)\n",
    "                gs_score[:, sensitivity_class] = 1.0\n",
    "                gs_score = model.backward_gradient(gs_score)\n",
    "                gs_score = torch.norm(gs_score, dim=-1)*torch.norm(gs_score, dim=-1)\n",
    "                if original_correct:\n",
    "                    new_gs_score = gs_score[tmp_idx_correct]\n",
    "                else:\n",
    "                    new_gs_score = gs_score[tmp_idx_wrong]\n",
    "                # rerun\n",
    "                for k_i in range(0, k):\n",
    "                    new_input_ids_curr = topk_drop(new_input_ids, new_gs_score, new_seq_lens, k=k_i+1)\n",
    "                    tmp_test_loss, logits, _, _ = \\\n",
    "                        model(new_input_ids_curr, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                                device=device, labels=new_label_ids)\n",
    "                    k_logits.append(logits)\n",
    "            elif del_type == \"gi\":\n",
    "                # GI dropouts\n",
    "                gi_score = torch.zeros(logits.shape)\n",
    "                gi_score[:, sensitivity_class] = 1.0\n",
    "                gi_score = model.backward_gradient_input(gi_score)\n",
    "                gi_score = torch.norm(gi_score, dim=-1)*torch.norm(gi_score, dim=-1)\n",
    "                if original_correct:\n",
    "                    new_gi_score = gi_score[tmp_idx_correct]\n",
    "                else:\n",
    "                    new_gi_score = gi_score[tmp_idx_wrong]\n",
    "                # rerun\n",
    "                for k_i in range(0, k):\n",
    "                    new_input_ids_curr = topk_drop(new_input_ids, new_gi_score, new_seq_lens, k=k_i+1)\n",
    "                    tmp_test_loss, logits, all_encoder_attention_scores, embedding_output = \\\n",
    "                        model(new_input_ids_curr, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                                device=device, labels=new_label_ids)\n",
    "                    k_logits.append(logits)\n",
    "            elif del_type == \"lrp\":\n",
    "                # lrp dropouts\n",
    "                Rout_mask = torch.zeros((input_ids.shape[0], len(label_list))).to(device)\n",
    "                Rout_mask[:, sensitivity_class] = 1.0\n",
    "                relevance_score = logits_raw*Rout_mask\n",
    "                lrp_score = model.backward_lrp(relevance_score)\n",
    "                lrp_score = lrp_score.cpu().detach().data\n",
    "                lrp_score = torch.abs(lrp_score).sum(dim=-1)\n",
    "                if original_correct:\n",
    "                    new_lrp_score = lrp_score[tmp_idx_correct]\n",
    "                else:\n",
    "                    new_lrp_score = lrp_score[tmp_idx_wrong]\n",
    "                # rerun\n",
    "                for k_i in range(0, k):\n",
    "                    new_input_ids_curr = topk_drop(new_input_ids, new_lrp_score, new_seq_lens, k=k_i+1)\n",
    "                    tmp_test_loss, logits, _, _ = \\\n",
    "                        model(new_input_ids_curr, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                                device=device, labels=new_label_ids)\n",
    "                    k_logits.append(logits)\n",
    "            elif del_type == \"lat\":\n",
    "                # lat dropouts\n",
    "                attention_scores = model.backward_lat(input_ids, all_encoder_attention_scores)\n",
    "                attention_scores = attention_scores.sum(dim=-1)\n",
    "                if original_correct:\n",
    "                    new_attention_scores = attention_scores[tmp_idx_correct]\n",
    "                else:\n",
    "                    new_attention_scores = attention_scores[tmp_idx_wrong]\n",
    "                # rerun\n",
    "                for k_i in range(0, k):\n",
    "                    new_input_ids_curr = topk_drop(new_input_ids, new_attention_scores, new_seq_lens, k=k_i+1)\n",
    "                    tmp_test_loss, logits, all_encoder_attention_scores, embedding_output = \\\n",
    "                        model(new_input_ids_curr, new_segment_ids, new_input_mask, new_seq_lens,\n",
    "                                device=device, labels=new_label_ids)\n",
    "                    k_logits.append(logits)\n",
    "        new_label_ids = new_label_ids.to('cpu').numpy()\n",
    "        for k_i in range(0, k):\n",
    "            logits = k_logits[k_i]\n",
    "            logits_raw = F.softmax(logits, dim=-1)\n",
    "            logits = logits_raw.detach().cpu().numpy()\n",
    "            outputs = np.argmax(logits, axis=1)\n",
    "            tmp_test_accuracy=np.sum(outputs == new_label_ids)\n",
    "            k_test_accuracy[k_i] = k_test_accuracy[k_i] + tmp_test_accuracy\n",
    "\n",
    "        nb_test_examples += new_input_ids.size(0) # same for all the ks\n",
    "        nb_test_steps += 1\n",
    "\n",
    "    for k_i in range(0, k):\n",
    "        test_accuracy = k_test_accuracy[k_i]\n",
    "        test_accuracy = test_accuracy / nb_test_examples\n",
    "        print(\"Drop words = %s, Accuracy = %.2f\"%(k_i+1, test_accuracy))\n",
    "    \n",
    "    for k_i in range(0, k):\n",
    "        test_accuracy = k_test_accuracy[k_i]\n",
    "        test_accuracy = test_accuracy / nb_test_examples\n",
    "        print(\"%.2f\"%(test_accuracy))\n",
    "\n",
    "def word_deletion_task(task_name, device, sentence_limit=2000, \n",
    "                       k=0, del_type=\"random\",\n",
    "                       original_correct=True):\n",
    "    \"\"\"\n",
    "    We need to set a limit otherwise it takes too long!\n",
    "    \"\"\"\n",
    "    TASK_NAME = task_name\n",
    "    lrp_data_dir = \"../../results\"\n",
    "    vocab_data_dir = \"../../models/BERT-Google/vocab.txt\"\n",
    "    DATA_DIR = \"../../datasets/\" + TASK_NAME + \"/\"\n",
    "\n",
    "    # \"../../data/uncased_L-12_H-768_A-12/\" is for the default BERT-base pretrain\n",
    "    BERT_PATH = \"../../models/BERT-Google/\"\n",
    "    MODEL_PATH = \"../../results/\" + TASK_NAME + \"/best_checkpoint.bin\"\n",
    "    EVAL_BATCH_SIZE = 24 # you can tune this down depends on GPU you have.\n",
    "\n",
    "    # This loads the task processor for you.\n",
    "    processors = {\n",
    "        \"SST5\": SST5_Processor,\n",
    "        \"SemEval\" : SemEval_Processor,\n",
    "        \"IMDb\" : IMDb_Processor,\n",
    "        \"Yelp5\" : Yelp5_Processor\n",
    "    }\n",
    "\n",
    "    processor = processors[TASK_NAME]()\n",
    "    label_list = processor.get_labels()\n",
    "    \n",
    "    model, tokenizer, optimizer = \\\n",
    "        load_model_setups(vocab_file=BERT_PATH + \"vocab.txt\",\n",
    "                           bert_config_file=BERT_PATH + \"bert_config.json\",\n",
    "                           init_checkpoint=MODEL_PATH,\n",
    "                           label_list=label_list,\n",
    "                           num_train_steps=20,\n",
    "                           do_lower_case=True,\n",
    "                           # below is not required for eval\n",
    "                           learning_rate=2e-5,\n",
    "                           warmup_proportion=0.1,\n",
    "                           init_lrp=True)\n",
    "    model = model.to(device) # send the model to device\n",
    "    \n",
    "    test_examples = processor.get_test_examples(DATA_DIR, sentence_limit=sentence_limit)\n",
    "    test_features = \\\n",
    "        convert_examples_to_features(\n",
    "            test_examples,\n",
    "            label_list,\n",
    "            128,\n",
    "            tokenizer)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
    "    all_seq_len = torch.tensor([[f.seq_len] for f in test_features], dtype=torch.long)\n",
    "\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                              all_label_ids, all_seq_len)\n",
    "\n",
    "    test_dataloader = DataLoader(test_data, batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    evaluate_with_word_deletion(test_dataloader, model, device, label_list, \n",
    "                                k=k, del_type=del_type, \n",
    "                                original_correct=original_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 15:00:20 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 15:00:20 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 15:00:20 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Word Deletion with Max K=10 =====\n",
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 47/1001 [00:00<00:02, 465.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 1000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\n",
      "text_b= None\n",
      "label= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:02<00:00, 499.79it/s]\n",
      "Iteration: 100%|██████████| 42/42 [02:44<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop words = 1, Accuracy = 0.98\n",
      "Drop words = 2, Accuracy = 0.97\n",
      "Drop words = 3, Accuracy = 0.95\n",
      "Drop words = 4, Accuracy = 0.93\n",
      "Drop words = 5, Accuracy = 0.92\n",
      "Drop words = 6, Accuracy = 0.88\n",
      "Drop words = 7, Accuracy = 0.89\n",
      "Drop words = 8, Accuracy = 0.88\n",
      "Drop words = 9, Accuracy = 0.86\n",
      "Drop words = 10, Accuracy = 0.83\n",
      "0.98\n",
      "0.97\n",
      "0.95\n",
      "0.93\n",
      "0.92\n",
      "0.88\n",
      "0.89\n",
      "0.88\n",
      "0.86\n",
      "0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# processors = {\n",
    "#     \"SST5\": SST5_Processor,\n",
    "#     \"SemEval\" : SemEval_Processor,\n",
    "#     \"IMDb\" : IMDb_Processor,\n",
    "#     \"Yelp5\" : Yelp5_Processor\n",
    "# }\n",
    "i = 10\n",
    "print(\"===== Word Deletion with Max K=%s =====\"%(i))\n",
    "word_deletion_task(\"Yelp5\", device, sentence_limit=1000, \n",
    "                   k=i, del_type=\"random\", \n",
    "                   original_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 15:03:08 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 15:03:08 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 15:03:08 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Word Deletion with Max K=10 =====\n",
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1001 [00:00<00:01, 535.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 1000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\n",
      "text_b= None\n",
      "label= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:01<00:00, 550.50it/s]\n",
      "Iteration: 100%|██████████| 42/42 [03:25<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop words = 1, Accuracy = 0.87\n",
      "Drop words = 2, Accuracy = 0.83\n",
      "Drop words = 3, Accuracy = 0.79\n",
      "Drop words = 4, Accuracy = 0.75\n",
      "Drop words = 5, Accuracy = 0.75\n",
      "Drop words = 6, Accuracy = 0.71\n",
      "Drop words = 7, Accuracy = 0.70\n",
      "Drop words = 8, Accuracy = 0.68\n",
      "Drop words = 9, Accuracy = 0.65\n",
      "Drop words = 10, Accuracy = 0.64\n",
      "0.87\n",
      "0.83\n",
      "0.79\n",
      "0.75\n",
      "0.75\n",
      "0.71\n",
      "0.70\n",
      "0.68\n",
      "0.65\n",
      "0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(\"===== Word Deletion with Max K=%s =====\"%(i))\n",
    "word_deletion_task(\"Yelp5\", device, sentence_limit=1000, \n",
    "                   k=i, del_type=\"gs\", \n",
    "                   original_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 15:06:38 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 15:06:38 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 15:06:38 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Word Deletion with Max K=10 =====\n",
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1001 [00:00<00:01, 557.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 1000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\n",
      "text_b= None\n",
      "label= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:01<00:00, 609.47it/s]\n",
      "Iteration: 100%|██████████| 42/42 [03:26<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop words = 1, Accuracy = 0.88\n",
      "Drop words = 2, Accuracy = 0.82\n",
      "Drop words = 3, Accuracy = 0.79\n",
      "Drop words = 4, Accuracy = 0.76\n",
      "Drop words = 5, Accuracy = 0.75\n",
      "Drop words = 6, Accuracy = 0.72\n",
      "Drop words = 7, Accuracy = 0.70\n",
      "Drop words = 8, Accuracy = 0.68\n",
      "Drop words = 9, Accuracy = 0.66\n",
      "Drop words = 10, Accuracy = 0.66\n",
      "0.88\n",
      "0.82\n",
      "0.79\n",
      "0.76\n",
      "0.75\n",
      "0.72\n",
      "0.70\n",
      "0.68\n",
      "0.66\n",
      "0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(\"===== Word Deletion with Max K=%s =====\"%(i))\n",
    "word_deletion_task(\"Yelp5\", device, sentence_limit=1000, \n",
    "                   k=i, del_type=\"gi\", \n",
    "                   original_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 15:10:07 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 15:10:07 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 15:10:07 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Word Deletion with Max K=10 =====\n",
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1001 [00:00<00:01, 477.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 1000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\n",
      "text_b= None\n",
      "label= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:01<00:00, 504.10it/s]\n",
      "Iteration: 100%|██████████| 42/42 [04:47<00:00,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop words = 1, Accuracy = 0.91\n",
      "Drop words = 2, Accuracy = 0.86\n",
      "Drop words = 3, Accuracy = 0.83\n",
      "Drop words = 4, Accuracy = 0.81\n",
      "Drop words = 5, Accuracy = 0.78\n",
      "Drop words = 6, Accuracy = 0.77\n",
      "Drop words = 7, Accuracy = 0.74\n",
      "Drop words = 8, Accuracy = 0.71\n",
      "Drop words = 9, Accuracy = 0.69\n",
      "Drop words = 10, Accuracy = 0.68\n",
      "0.91\n",
      "0.86\n",
      "0.83\n",
      "0.81\n",
      "0.78\n",
      "0.77\n",
      "0.74\n",
      "0.71\n",
      "0.69\n",
      "0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(\"===== Word Deletion with Max K=%s =====\"%(i))\n",
    "word_deletion_task(\"Yelp5\", device, sentence_limit=1000, \n",
    "                   k=i, del_type=\"lrp\", \n",
    "                   original_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/29/2020 15:14:58 - INFO - run_classifier -   model = BERT\n",
      "12/29/2020 15:14:58 - INFO - run_classifier -   *** Model Config ***\n",
      "12/29/2020 15:14:58 - INFO - run_classifier -   {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"full_pooler\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Word Deletion with Max K=10 =====\n",
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1001 [00:00<00:01, 509.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence limit= 1000\n",
      "0\n",
      "guid= test-0\n",
      "text_a= Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\n",
      "text_b= None\n",
      "label= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:01<00:00, 629.18it/s]\n",
      "Iteration: 100%|██████████| 42/42 [02:45<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop words = 1, Accuracy = 0.99\n",
      "Drop words = 2, Accuracy = 0.96\n",
      "Drop words = 3, Accuracy = 0.95\n",
      "Drop words = 4, Accuracy = 0.93\n",
      "Drop words = 5, Accuracy = 0.92\n",
      "Drop words = 6, Accuracy = 0.90\n",
      "Drop words = 7, Accuracy = 0.88\n",
      "Drop words = 8, Accuracy = 0.87\n",
      "Drop words = 9, Accuracy = 0.85\n",
      "Drop words = 10, Accuracy = 0.83\n",
      "0.99\n",
      "0.96\n",
      "0.95\n",
      "0.93\n",
      "0.92\n",
      "0.90\n",
      "0.88\n",
      "0.87\n",
      "0.85\n",
      "0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(\"===== Word Deletion with Max K=%s =====\"%(i))\n",
    "word_deletion_task(\"Yelp5\", device, sentence_limit=1000, \n",
    "                   k=i, del_type=\"lat\", \n",
    "                   original_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 3.4 Correlations across datasets\n",
    "Due to the memory limitation and cache limitations, we want run these analysis function 1 at a time to avoid failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_dict = analysis_task(\"SST5\", device)\n",
    "torch.save(sst5_dict, \"./sst5_dict.pt\")\n",
    "semeval_dict = analysis_task(\"SemEval\", device)\n",
    "torch.save(semeval_dict, \"./semeval.pt\")\n",
    "imdb_dict = analysis_task(\"IMDb\", device)\n",
    "torch.save(imdb_dict, \"./imdb.pt\")\n",
    "yelp5_dict = analysis_task(\"Yelp5\", device)\n",
    "torch.save(yelp5_dict, \"./yelp5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    sst5_dict = analysis_task(\"SST5\", device)\n",
    "    torch.save(sst5_dict, \"./sst5_dict.pt\")\n",
    "    semeval_dict = analysis_task(\"SemEval\", device)\n",
    "    torch.save(semeval_dict, \"./semeval.pt\")\n",
    "    imdb_dict = analysis_task(\"IMDb\", device)\n",
    "    torch.save(imdb_dict, \"./imdb.pt\")\n",
    "    yelp5_dict = analysis_task(\"Yelp5\", device)\n",
    "    torch.save(yelp5_dict, \"./yelp5.pt\")\n",
    "else:\n",
    "    sst5_dict = torch.load(\"./sst5_dict.pt\")\n",
    "    semeval_dict = torch.load(\"./semeval.pt\")\n",
    "    imdb_dict = torch.load(\"./imdb.pt\")\n",
    "    yelp5_dict = torch.load(\"./yelp5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_word_to_score = load_word_score(vocab_data_dir, \n",
    "                                     sst5_dict[\"inputs_ids\"], \n",
    "                                     sst5_dict[\"seqs_lens\"],\n",
    "                                     sst5_dict[\"grad_scores\"])\n",
    "semeval_word_to_score = load_word_score(vocab_data_dir, \n",
    "                                     semeval_dict[\"inputs_ids\"], \n",
    "                                     semeval_dict[\"seqs_lens\"],\n",
    "                                     semeval_dict[\"grad_scores\"])\n",
    "imdb_word_to_score = load_word_score(vocab_data_dir, \n",
    "                                     imdb_dict[\"inputs_ids\"], \n",
    "                                     imdb_dict[\"seqs_lens\"],\n",
    "                                     imdb_dict[\"grad_scores\"])\n",
    "yelp5_word_to_score = load_word_score(vocab_data_dir, \n",
    "                                     yelp5_dict[\"inputs_ids\"], \n",
    "                                     yelp5_dict[\"seqs_lens\"],\n",
    "                                     yelp5_dict[\"grad_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = subset_score([sst5_word_to_score, semeval_word_to_score, imdb_word_to_score, yelp5_word_to_score])\n",
    "score_df = pd.DataFrame({\"sst5\": sst5_word_to_score, \"semeval\": semeval_word_to_score,\n",
    "                         \"imdb\": imdb_word_to_score, \"yelp5\": yelp5_word_to_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = \"black\"\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "y = score_list[1]\n",
    "x = score_list[0]\n",
    "\n",
    "plt.scatter(x, y, marker='*', color='r')\n",
    "plt.tight_layout()\n",
    "plt.grid(color='black', linestyle='-.')\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def reg_coef(x,y,label=None,color=None,**kwargs):\n",
    "    ax = plt.gca()\n",
    "    r,p = pearsonr(x,y)\n",
    "    ax.annotate('r = {:.2f}'.format(r), xy=(0.5,0.5), xycoords='axes fraction', ha='center', size=30)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "g = sns.PairGrid(score_df)\n",
    "g.map_diag(sns.distplot)\n",
    "g.map_lower(sns.regplot, marker=\"+\", line_kws={\"color\": \"red\"})\n",
    "g.map_upper(reg_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
